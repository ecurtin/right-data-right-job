spark-bench = {
  spark-submit-parallel = false
  spark-submit-config = [
    {
      spark-home = "/opt/spark-dists/spark"
      spark-args = {
        master = "spark://devnexus-master:7077"
        executor-memory = "14g"
        total-executor-cores = "40"
    }
    workload-suites = [
      {
        descr = "Read in CSV, write out as CSV with one giant partition"
        benchmark-output = "hdfs:///devnexus/benchmarks.csv"
        save-mode = "append"
        repeat = 10
        workloads = [
          {
            name = "sql"
            query = ["select * from input", "select c1, c24 from input where c1 < -0.9"]
            input = [
              "hdfs:///devnexus/kmeans-data-gzip.parquet",
              "hdfs:///devnexus/kmeans-data-one-partition.csv",
              "hdfs:///devnexus/kmeans-data-orc.orc",
              "hdfs:///devnexus/kmeans-data-snappy.parquet",
              "hdfs:///devnexus/kmeans-data-uncompressed.parquet",
              "hdfs:///devnexus/kmeans-data.csv"
            ]
          }
          {
            name = "kmeans"
            input = [
              "hdfs:///devnexus/kmeans-data-gzip.parquet",
              "hdfs:///devnexus/kmeans-data-one-partition.csv",
              "hdfs:///devnexus/kmeans-data-orc.orc",
              "hdfs:///devnexus/kmeans-data-snappy.parquet",
              "hdfs:///devnexus/kmeans-data-uncompressed.parquet",
              "hdfs:///devnexus/kmeans-data.csv"
            ]
            k = 100
          }
        ]

      }]
  }]
}