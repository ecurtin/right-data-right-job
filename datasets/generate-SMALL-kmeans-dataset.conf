spark-bench = {
  spark-submit-parallel = false
  spark-submit-config = [
  {
    spark-home = "/opt/spark-dists/spark"
    spark-args = {
      master = "spark://devnexus-master:7077"
      executor-memory = "14g"
      total-executor-cores = "40"
    }
    workload-suites = [
      {
        descr = "Generating CSV of kmeans data"
        benchmark-output = "hdfs:///devnexus/small/data-generation.csv"
        save-mode = "append"
        workloads = [
          {
            name = "data-generation-kmeans"
            rows = 100000
            cols = 15
            partitions = 5
            save-mode = "ignore"
            output = "hdfs:///devnexus/small/kmeans-data.csv"
          }
        ]
      }
    ]
  },
  {
    spark-home = "/opt/spark-dists/spark"
    spark-args = {
      master = "spark://devnexus-master:7077"
      executor-memory = "14g"
      total-executor-cores = "40"
    }
    conf = {
      "spark.sql.parquet.compression.codec" = "uncompressed"
    }
    workload-suites = [
      {
        descr = "Read in CSV, write as Uncompressed Parquet"
        benchmark-output = "hdfs:///devnexus/small/data-generation.csv"
        save-mode = "append"
        workloads = [
          {
            name = "sql"
            query = "select * from input"
            save-mode = "ignore"
            input = "hdfs:///devnexus/small/kmeans-data.csv"
            output = "hdfs:///devnexus/small/kmeans-data-uncompressed.parquet"
          }
        ]
      }
    ]
  },
  {
    spark-home = "/opt/spark-dists/spark"
    spark-args = {
      master = "spark://devnexus-master:7077"
      executor-memory = "14g"
      total-executor-cores = "40"
    }
    conf = {
      "spark.sql.parquet.compression.codec" = "gzip"
    }
    workload-suites = [
      {
        descr = "Read in CSV, write as GZIP Parquet"
        benchmark-output = "hdfs:///devnexus/small/data-generation.csv"
        save-mode = "append"
        workloads = [
          {
            name = "sql"
            query = "select * from input"
            save-mode = "ignore"
            input = "hdfs:///devnexus/small/kmeans-data.csv"
            output = "hdfs:///devnexus/small/kmeans-data-gzip.parquet"
          }
        ]
      }
    ]
  },
  {
    spark-home = "/opt/spark-dists/spark"
    spark-args = {
      master = "spark://devnexus-master:7077"
      executor-memory = "14g"
      total-executor-cores = "40"
    }
    conf = {
      "spark.sql.parquet.compression.codec" = "snappy"
    }
    workload-suites = [
      {
        descr = "Read in CSV, write as Snappy Parquet"
        benchmark-output = "hdfs:///devnexus/small/data-generation.csv"
        save-mode = "append"
        workloads = [
          {
            name = "sql"
            query = "select * from input"
            save-mode = "ignore"
            input = "hdfs:///devnexus/small/kmeans-data.csv"
            output = "hdfs:///devnexus/small/kmeans-data-snappy.parquet"
          }
        ]
      }
    ]
  },
  {
    spark-home = "/opt/spark-dists/spark"
    spark-args = {
      master = "spark://devnexus-master:7077"
      executor-memory = "14g"
      total-executor-cores = "40"
    }
    workload-suites = [
      {
        descr = "Read in CSV, write as Avro"
        benchmark-output = "hdfs:///devnexus/small/data-generation.csv"
        save-mode = "append"
        workloads = [
          {
            name = "sql"
            query = "select * from input"
            save-mode = "ignore"
            input = "hdfs:///devnexus/small/kmeans-data.csv"
            output = ["hdfs:///devnexus/small/kmeans-data-avro.avro", "hdfs:///devnexus/small/kmeans-data-orc.orc"]
          }
        ]
      }
    ]
  }
  ]
}
